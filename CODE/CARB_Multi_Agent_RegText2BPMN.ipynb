{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvSshmZo-9L1"
      },
      "outputs": [],
      "source": [
        "# general\n",
        "!pip install langchain langgraph langchain_google_genai langgraph_supervisor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndJqC5ix8dcQ"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade langgraph langchain-core langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3EJiWRbstYS"
      },
      "outputs": [],
      "source": [
        "# for bpmn linter tool\n",
        "\n",
        "# 1. Forcefully remove the specific conflicting package from the old installation\n",
        "!sudo dpkg --remove --force-remove-reinstreq libnode-dev\n",
        "\n",
        "# 2. Purge any other old Node.js/npm packages to be safe\n",
        "!sudo apt-get purge -y nodejs npm\n",
        "\n",
        "# 3. Automatically remove all unused leftover dependencies\n",
        "!sudo apt autoremove -y\n",
        "\n",
        "# 4. Now, set up the source for Node.js v20\n",
        "!curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash -\n",
        "\n",
        "# 5. Install Node.js v20 and its compatible npm\n",
        "!sudo apt-get install -y nodejs\n",
        "\n",
        "# 6. Finally, install bpmnlint\n",
        "!npm install -g bpmnlint\n",
        "\n",
        "print(\"bpmnlint installation complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84E6QAmRxqoI"
      },
      "outputs": [],
      "source": [
        "#create local .bpmnlintrc file\n",
        "!bpmnlint --init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_RszgDX2cEV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from google.colab import userdata\n",
        "\n",
        "#setup the api key\n",
        "os.environ['GOOGLE_API_KEY']=userdata.get('Google_API_Key')\n",
        "print('Success!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaDAE8Q-183O"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import requests\n",
        "import time\n",
        "import json\n",
        "import subprocess\n",
        "from typing import List, Dict, TypedDict, Annotated\n",
        "from langgraph.graph import StateGraph, START, MessagesState, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.load import dumps, loads\n",
        "from langgraph.types import Command\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain.tools import StructuredTool\n",
        "from langchain_core.runnables import Runnable, RunnableConfig\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langchain_core.tools import tool\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
        "from langchain.tools import tool\n",
        "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGKet2eUemwl"
      },
      "outputs": [],
      "source": [
        "# main script\n",
        "# to run on your own use cases you simply have to upload your input texts as \"uc1.txt-uc5.txt\" in colab;\n",
        "# if oyu prefer to change the input file name/path you'd have to do that in the main execution section at the bottom of this cell\n",
        "\n",
        "@tool\n",
        "def validate_bpmn_file(file_path: str):\n",
        "    \"\"\"\n",
        "    Validates a .bpmn file against BPMN 2.0 standards using the bpmnlint linter.\n",
        "    It checks for common modeling errors and best practices.\n",
        "    The parameter `file_path` is the local path to the .bpmn file to be validated.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(file_path):\n",
        "        return f\"Error: File not found at '{file_path}'\"\n",
        "    try:\n",
        "        command = [\"bpmnlint\", file_path]\n",
        "        result = subprocess.run(command, capture_output=True, text=True, check=False)\n",
        "        if result.returncode != 0:\n",
        "            error_details = result.stdout + result.stderr\n",
        "            return f\"BPMN file is INVALID. \\n--- Linter Errors ---\\n{error_details}\"\n",
        "        else:\n",
        "            return \"BPMN file is VALID.\"\n",
        "    except FileNotFoundError:\n",
        "        return \"Error: 'bpmnlint' command not found. Please ensure it is installed and in your PATH.\"\n",
        "    except Exception as e:\n",
        "        return f\"An unexpected error occurred: {e}\"\n",
        "\n",
        "@tool\n",
        "def read_file(file_path: str) -> str:\n",
        "    \"\"\"Reads the entire content of a file and returns it as a string.\"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            return f.read()\n",
        "    except Exception as e:\n",
        "        return f\"Error reading file: {e}\"\n",
        "\n",
        "@tool\n",
        "def write_file(file_path: str, content: str) -> str:\n",
        "    \"\"\"\n",
        "    Writes the given content to a file, overwriting it if it exists.\n",
        "    Includes a short pause to prevent race conditions.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(content)\n",
        "        # Add a 1-second pause to ensure the file system has time to process the write.\n",
        "        time.sleep(1)\n",
        "        return f\"Successfully wrote content to {file_path}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error writing file: {e}\"\n",
        "\n",
        "# --- AGENT DEFINITIONS ---\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\", temperature=0.0)\n",
        "\n",
        "# BASE AGENT\n",
        "base_system_message = \"\"\"\n",
        "You are a BPMN 2.0 Modeler Agent. Your input will be a string with two file paths separated by a comma: the source text path, and the target BPMN file path for your output.\n",
        "\n",
        "### Your Instructions:\n",
        "1.  Parse the two paths from the input string.\n",
        "2.  Your first action MUST be to use the `read_file` tool to get the content of the source text path.\n",
        "3.  Generate a complete BPMN 2.0 XML structure based on the text.\n",
        "    - include all involved entities from the text as pools (do not use (swim)lanes but put each participant in their own pool)\n",
        "    - pay attention to gateways: these should represent conditions form the text; if not all incoming paths are required, you should choose a XOR join, not an AND join; a gateway is either a split or join not both\n",
        "    - there should only be one incoming and one outgoing flow from events and tasks (exceptions for e.g. end events that should not have any outgoing flows of course)\n",
        "    - **CRITICAL:** You MUST include the complete `<bpmndi:BPMNDiagram>` section. Every single element (actors, tasks, events, flows, etc.) MUST have a corresponding visual element (`<bpmndi:BPMNShape>` or `<bpmndi:BPMNEdge>`). An incomplete diagram is a failure.\n",
        "4.  Your final action MUST be a single call to the `write_file` tool to save your generated XML to the target BPMN file path.\n",
        "5.  After calling the tool, respond with a simple confirmation like \"BPMN XML generated and saved.\"\n",
        "\"\"\"\n",
        "\n",
        "bpmn_modeler_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", base_system_message),\n",
        "    (\"human\", \"{input}\"),\n",
        "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "])\n",
        "bpmn_modeler_tools = [write_file, read_file]\n",
        "bpmn_modeler_agent = create_tool_calling_agent(llm, bpmn_modeler_tools, bpmn_modeler_prompt)\n",
        "bpmn_modeler_executor = AgentExecutor(agent=bpmn_modeler_agent, tools=bpmn_modeler_tools, verbose=True)\n",
        "\n",
        "\n",
        "# SYNTAX AGENT\n",
        "syntax_system_message = \"\"\"\n",
        "You are a meticulous BPMN Syntax Corrector Agent. Your input will be a single file path to a BPMN file.\n",
        "\n",
        "### Your Workflow (Follow this strictly):\n",
        "1.  Your first action is to call the `validate_bpmn_file` tool on the file path from your input.\n",
        "2.  **Analyze the Validation Result:**\n",
        "    -   **If the result is \"BPMN file is VALID.\":** Your job is done. Respond with \"BPMN file is valid.\"\n",
        "    -   **If the result contains \"Error: File not found\":** Report this critical error to the supervisor.\n",
        "    -   **If the result is \"BPMN file is INVALID.\":** You must now enter a correction loop.\n",
        "        a. Use `read_file` to get the current broken XML from the input file path.\n",
        "        b. Analyze the \"Linter Errors\" from the validation result and identify the necessary corrections.\n",
        "        If you add e.g. events between tasks, make sure these are intermediate events. Usually an XOR split gateway should be eventually followed by an XOR join. Make sure you do not create deadlocks by using AND joins when in reality it should be a XOR join.\n",
        "        Make sure the elements you create are correctly connected, e.g. flows are connected to element and to not eng in nowhere.\n",
        "        c. **Generate the corrected XML in your thought process.** You must take the entire original XML content and apply the necessary fixes.\n",
        "        d. **Your final action MUST be a single tool call to `write_file`. The `content` parameter for this tool call must be the *entire, complete, and corrected* BPMN XML string, and the `file_path` must be the same one from your input.**\n",
        "        e. Go back to step 1 and re-validate your own work.\n",
        "\"\"\"\n",
        "syntax_corrector_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", syntax_system_message),\n",
        "    (\"human\", \"{input}\"),\n",
        "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "])\n",
        "syntax_corrector_tools = [read_file, write_file, validate_bpmn_file]\n",
        "syntax_corrector_agent = create_tool_calling_agent(llm, syntax_corrector_tools, syntax_corrector_prompt)\n",
        "syntax_corrector_executor = AgentExecutor(agent=syntax_corrector_agent, tools=syntax_corrector_tools, verbose=True)\n",
        "\n",
        "\n",
        "# LAYOUT AGENT\n",
        "layout_system_message = \"\"\"\n",
        "You are an expert BPMN Layout Specialist, obsessed with creating clean, professional, and easy-to-read diagrams. Your input will be a single file path to a BPMN file. Your sole purpose is to perform a single, effective pass of layout correction.\n",
        "\n",
        "### Your Workflow:\n",
        "1.  **Read and Analyze:** Use the `read_file` tool to get the current BPMN XML content. Then, in your thought process, perform a comprehensive analysis based on the following **Layout Heuristics**:\n",
        "\n",
        "    **Layout Heuristics (Apply all):**\n",
        "    1.  **Strict Containment:** Absolutely NO element's bounds (`<dc:Bounds>`) may extend beyond the boundaries of its parent Pool or Lane. This is a critical error to fix.\n",
        "    2.  **Eliminate Overlaps:**\n",
        "        -   No two shapes (`<bpmndi:BPMNShape>`) can overlap.\n",
        "        -   No label (`<bpmndi:BPMNLabel>`) can overlap with any part of another shape or a sequence flow line. Pay special attention to gateway labels; place them in a clear space adjacent to the gateway, not obstructing any flows.\n",
        "    3.  **Enforce Orthogonal Flows:** ALL sequence flows (`<bpmndi:BPMNEdge>`) MUST be composed of horizontal and vertical line segments. For any two consecutive waypoints, either their x-coordinates or their y-coordinates MUST be identical. Correct any diagonal lines.\n",
        "    4.  **Minimize Flow Crossings:** Reroute flows to go around other elements rather than through them. While some crossings may be unavoidable, they should be minimized and clean (perfect 90-degree intersections).\n",
        "\n",
        "2.  **Decision and Execution:**\n",
        "    -   **If you find NO layout issues** according to the heuristics above: Your job for this turn is done. Respond with the exact message: \"Layout analysis complete. No issues found.\"\n",
        "    -   **If you DO find layout issues:** You must fix them all at once.\n",
        "        a. **Create a comprehensive plan** to fix ALL identified issues based on the heuristics.\n",
        "        b. **Generate the corrected XML.** You must take the entire original XML content and apply ALL the necessary coordinate changes to create a single, corrected version of the file.\n",
        "        c. **Your final action MUST be a single tool call to `write_file`. The `content` parameter must be the *entire, complete, and corrected* BPMN XML string, and the `file_path` must be the same one from your input.** After the tool call, respond with a summary of the changes you made.\n",
        "\"\"\"\n",
        "layout_corrector_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", layout_system_message),\n",
        "    (\"human\", \"{input}\"),\n",
        "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "])\n",
        "layout_corrector_tools = [read_file, write_file]\n",
        "layout_corrector_agent = create_tool_calling_agent(llm, layout_corrector_tools, layout_corrector_prompt)\n",
        "layout_corrector_executor = AgentExecutor(agent=layout_corrector_agent, tools=layout_corrector_tools, verbose=True)\n",
        "\n",
        "\n",
        "# SEMANTIC LOGIC AGENT\n",
        "semantic_system_message = \"\"\"\n",
        "You are an expert BPMN Semantic Corrector Agent. Your input will be a string with two file paths separated by a comma: the source text path and the BPMN file path. Your sole purpose is to perform a single, effective pass of semantic correction.\n",
        "\n",
        "### Your Workflow:\n",
        "1.  **Parse and Read Files:** Parse the two paths from the input string. Use the `read_file` tool twice: once for the source text and once for the BPMN XML file.\n",
        "\n",
        "2.  **Analyze and Compare:** In your own thought process, perform a detailed analysis to find ALL discrepancies between the source text and the BPMN model.\n",
        "\n",
        "    **Analysis Task:**\n",
        "    1.  **Completeness Check:** First, ensure all major actors, activities, and events described in the text are present in the BPMN model.\n",
        "    2.  **Regulatory & Logic Check:** Pay special attention to the following types of rules and evaluate their implementation in the model:\n",
        "        -   **Conditional Clauses:** Are `if/then` statements correctly modeled with gateways?\n",
        "        -   **Temporal Constraints:** Are time-based rules (e.g., \"within 3 days\") modeled with timer events?\n",
        "        -   **Obligatory Actions:** Are words like `must`, `shall`, `has to` modeled as part of a non-optional execution path?\n",
        "        -   **Prohibited Actions:** Are phrases like `must not` correctly modeled as impossible paths or explicit exception flows?\n",
        "        -   **Permitted Actions:** Are words like `can` or `may` correctly modeled as optional paths, for example, following a choice gateway?\n",
        "\n",
        "3.  **Decision and Execution:**\n",
        "    -   **If you find NO discrepancies:** Your job for this turn is done. Respond with the exact message: \"Semantic analysis complete. The model accurately represents the source text.\"\n",
        "    -   **If you DO find discrepancies:** You must fix them all at once.\n",
        "        a. **Plan your changes** for all identified issues.\n",
        "        b. **Generate the corrected XML.** You must take the entire original BPMN XML and modify the logical elements to fix ALL the reported errors. Do not create subprocess or add very uncommon BPMN elements.\n",
        "        c. **Your final action MUST be a single tool call to `write_file`. The `content` parameter must be the *entire, complete, and corrected* BPMN XML string, and the `file_path` must be the BPMN path from your input.** After the tool call, respond with a summary of the changes you made.\n",
        "\"\"\"\n",
        "semantic_corrector_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", semantic_system_message),\n",
        "    (\"human\", \"{input}\"),\n",
        "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "])\n",
        "semantic_logic_tools = [read_file, write_file]\n",
        "semantic_logic_agent = create_tool_calling_agent(llm, semantic_logic_tools, semantic_corrector_prompt)\n",
        "semantic_logic_executor = AgentExecutor(agent=semantic_logic_agent, tools=semantic_logic_tools, verbose=True)\n",
        "\n",
        "\n",
        "# --- SUPERVISOR AND GRAPH SETUP ---\n",
        "\n",
        "supervisor_system_message = \"\"\"\n",
        "You are a master supervisor of a team of BPMN specialist agents. Your job is to manage a workflow from text-to-perfect BPMN by giving clear, concise tasks to your workers.\n",
        "\n",
        "Your team consists of:\n",
        "1. **bpmn_modeler_agent**: Creates the initial draft.\n",
        "2. **syntax_corrector_agent**: Checks for syntax errors.\n",
        "3. **semantic_logic_agent**: Checks for semantic errors against the source text.\n",
        "4. **layout_corrector_agent**: Checks for visual layout errors.\n",
        "\n",
        "### Your Workflow Rules:\n",
        "\n",
        "1. **Modeling (CRITICAL RULE)**:\n",
        "   Your first task is to call `bpmn_modeler_agent`. Under NO circumstances should you call this agent again after it has run once.\n",
        "\n",
        "2. **Correction Cycle (Syntax & Semantics)**:\n",
        "   - Your goal is to get a \"pass\" from the agents in this order: `syntax_corrector_agent` → `semantic_logic_agent`.\n",
        "   - These two agents are part of the **main correction loop**.\n",
        "   - If either agent makes a correction and is still within its attempt limit, you must restart the loop by calling `syntax_corrector_agent` again.\n",
        "   - If `semantic_logic_agent` passes, **or** has reached its 2-attempt limit, the main correction loop is considered complete.\n",
        "\n",
        "3. **Final Layout Step**:\n",
        "   - After the syntax and semantic steps are complete, you must call `layout_corrector_agent` **once**.\n",
        "   - If `layout_corrector_agent` passes (finds no issues), the entire process is complete. Respond with `\"END\"`.\n",
        "   - If it makes a correction, perform a final safety check by calling `syntax_corrector_agent`.\n",
        "   - If this final syntax check passes, the process is complete. Respond with `\"END\"`.\n",
        "\n",
        "### Decision Logic (VERY IMPORTANT):\n",
        "Your decision MUST be based on the most recent message in the history.\n",
        "\n",
        "- If the last message is `\"BPMN file is valid.\"`, call `semantic_logic_agent`.\n",
        "- If the last message is `\"Semantic analysis complete. The model accurately represents the source text.\"`, call `layout_corrector_agent`.\n",
        "- If the last message is `\"Layout analysis complete. No issues found.\"`, the job is done. Call `\"END\"`.\n",
        "- If any agent reports it made a correction, call `syntax_corrector_agent`, **except**:\n",
        "    - If `layout_corrector_agent` made a correction, and the **subsequent** `syntax_corrector_agent` call passed, the job is done. Call `\"END\"`.\n",
        "\n",
        "- **IMPORTANT**: You must not call `\"END\"` unless:\n",
        "    - `layout_corrector_agent` has run **at least once**, and\n",
        "    - Either it passed, or it made a correction followed by a passing `syntax_corrector_agent`.\n",
        "\n",
        "### Output Format:\n",
        "Your response MUST be a JSON object with two keys:\n",
        "- `\"next_agent\"`: The string name of the next agent to call (e.g., `\"syntax_corrector_agent\"`) or `\"END\"`.\n",
        "- `\"task_description\"`: A string containing ONLY the required file path(s) for the agent.\n",
        "    - For `bpmn_modeler_agent`: Provide a string like `\"source_path,target_path\"`.\n",
        "    - For `syntax_corrector_agent` and `layout_corrector_agent`: Provide the single path to the BPMN file.\n",
        "    - For `semantic_logic_agent`: Provide a string like `\"source_path,bpmn_path\"`.\n",
        "\"\"\"\n",
        "\n",
        "supervisor_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", supervisor_system_message),\n",
        "    (\"placeholder\", \"{messages}\"),\n",
        "])\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[List[BaseMessage], lambda x, y: x + y]\n",
        "    task: str\n",
        "    next: str\n",
        "    file_path: str\n",
        "    source_path: str\n",
        "    attempt_counts: Dict[str, int]\n",
        "    agent_step_counts: Dict[str, int]\n",
        "    modeler_has_run: bool\n",
        "\n",
        "class SupervisorDecision(TypedDict):\n",
        "    next_agent: str\n",
        "    task_description: str\n",
        "\n",
        "supervisor_chain = supervisor_prompt | llm.with_structured_output(SupervisorDecision)\n",
        "\n",
        "def supervisor_node(state: AgentState):\n",
        "    \"\"\"\n",
        "    Calls the supervisor to decide the next step and enforces workflow rules.\n",
        "    \"\"\"\n",
        "    if state.get(\"attempt_counts\") is None:\n",
        "        state[\"attempt_counts\"] = {}\n",
        "    if state.get(\"agent_step_counts\") is None:\n",
        "        state[\"agent_step_counts\"] = {}\n",
        "\n",
        "    time.sleep(0.5)\n",
        "\n",
        "    messages_for_supervisor = state['messages']\n",
        "\n",
        "    context_message = HumanMessage(\n",
        "        content=f\"SYSTEM CONTEXT: The primary BPMN file is '{state['file_path']}'. The source text is at '{state['source_path']}'. Modeler has run: {state.get('modeler_has_run', False)}. Current attempt counts: {state.get('attempt_counts')}\",\n",
        "        name=\"System\"\n",
        "    )\n",
        "    messages_for_supervisor = [context_message] + messages_for_supervisor\n",
        "\n",
        "    decision = supervisor_chain.invoke({\"messages\": messages_for_supervisor})\n",
        "    next_agent = decision['next_agent']\n",
        "    task_description = decision['task_description']\n",
        "\n",
        "    last_agent_name = \"\"\n",
        "    if state['messages']:\n",
        "        for msg in reversed(state['messages']):\n",
        "            if isinstance(msg, AIMessage):\n",
        "                last_agent_name = msg.name\n",
        "                break\n",
        "\n",
        "    semantic_attempts = state[\"attempt_counts\"].get(\"semantic_logic_agent\", 0)\n",
        "    if last_agent_name == \"semantic_logic_agent\" and semantic_attempts >= 3:\n",
        "        print(\"--- SEMANTIC AGENT MAX ATTEMPTS REACHED. Forcing progression to layout agent. ---\")\n",
        "        next_agent = \"layout_corrector_agent\"\n",
        "        task_description = state['file_path']\n",
        "\n",
        "    if state.get(\"modeler_has_run\") and next_agent == \"bpmn_modeler_agent\":\n",
        "        print(\"--- SUPERVISOR ERROR OVERRIDE: Attempted to call modeler again. Redirecting to syntax_corrector_agent. ---\")\n",
        "        next_agent = \"syntax_corrector_agent\"\n",
        "        task_description = state['file_path']\n",
        "\n",
        "    if next_agent != \"END\":\n",
        "        current_attempts = state[\"attempt_counts\"].get(next_agent, 0)\n",
        "        state[\"attempt_counts\"][next_agent] = current_attempts + 1\n",
        "\n",
        "        if next_agent == \"syntax_corrector_agent\":\n",
        "            max_attempts = 6\n",
        "        elif next_agent == \"semantic_logic_agent\":\n",
        "            max_attempts = 2\n",
        "        elif next_agent == \"layout_corrector_agent\":\n",
        "            max_attempts = 1\n",
        "        else:\n",
        "            max_attempts = 1 # Default for modeler\n",
        "\n",
        "        if current_attempts >= max_attempts:\n",
        "            print(f\"--- MAX ATTEMPTS REACHED FOR AGENT: {next_agent} ({max_attempts} attempts). Aborting. ---\")\n",
        "            last_bpmn_content = read_file.invoke({\"file_path\": state['file_path']})\n",
        "            final_message = (\n",
        "                f\"Process aborted after {max_attempts} failed attempts by {next_agent}.\\n\\n\"\n",
        "                f\"Here is the last available version of the BPMN file:\\n\\n\"\n",
        "                f\"```xml\\n{last_bpmn_content}\\n```\"\n",
        "            )\n",
        "            return {\"next\": \"END\", \"messages\": [HumanMessage(content=final_message)]}\n",
        "\n",
        "    return {\n",
        "        \"next\": next_agent,\n",
        "        \"task\": task_description,\n",
        "        \"attempt_counts\": state[\"attempt_counts\"],\n",
        "        \"messages\": [],\n",
        "    }\n",
        "\n",
        "def worker_node(state: AgentState, agent_executor: AgentExecutor, agent_name: str):\n",
        "    \"\"\"\n",
        "    Runs a worker agent on its assigned task and saves an intermediate snapshot of the BPMN file.\n",
        "    \"\"\"\n",
        "    result = agent_executor.invoke({\"input\": state[\"task\"]})\n",
        "\n",
        "    if agent_name == \"bpmn_modeler_agent\":\n",
        "        state[\"modeler_has_run\"] = True\n",
        "\n",
        "    current_step_count = state[\"agent_step_counts\"].get(agent_name, 0) + 1\n",
        "    state[\"agent_step_counts\"][agent_name] = current_step_count\n",
        "\n",
        "    if os.path.exists(state['file_path']):\n",
        "        content = read_file.invoke({\"file_path\": state['file_path']})\n",
        "        base, ext = os.path.splitext(state['file_path'])\n",
        "        safe_agent_name = agent_name.replace('_agent', '')\n",
        "        intermediate_filename = f\"{base}_{safe_agent_name}_{current_step_count}{ext}\"\n",
        "        write_file.invoke({\"file_path\": intermediate_filename, \"content\": content})\n",
        "        print(f\"--- Saved intermediate state to {intermediate_filename} ---\")\n",
        "\n",
        "    return {\n",
        "        \"messages\": [AIMessage(content=result[\"output\"], name=agent_name)],\n",
        "        \"agent_step_counts\": state[\"agent_step_counts\"],\n",
        "        \"modeler_has_run\": state.get(\"modeler_has_run\", False),\n",
        "    }\n",
        "\n",
        "\n",
        "# Building graph\n",
        "workflow = StateGraph(AgentState)\n",
        "workflow.add_node(\"supervisor\", supervisor_node)\n",
        "workflow.add_node(\"bpmn_modeler_agent\", lambda state: worker_node(state, bpmn_modeler_executor, \"bpmn_modeler_agent\"))\n",
        "workflow.add_node(\"syntax_corrector_agent\", lambda state: worker_node(state, syntax_corrector_executor, \"syntax_corrector_agent\"))\n",
        "workflow.add_node(\"layout_corrector_agent\", lambda state: worker_node(state, layout_corrector_executor, \"layout_corrector_agent\"))\n",
        "workflow.add_node(\"semantic_logic_agent\", lambda state: worker_node(state, semantic_logic_executor, \"semantic_logic_agent\"))\n",
        "\n",
        "def router(state: AgentState):\n",
        "    return state['next']\n",
        "\n",
        "workflow.set_entry_point(\"supervisor\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"supervisor\",\n",
        "    router,\n",
        "    {\n",
        "        \"bpmn_modeler_agent\": \"bpmn_modeler_agent\",\n",
        "        \"syntax_corrector_agent\": \"syntax_corrector_agent\",\n",
        "        \"layout_corrector_agent\": \"layout_corrector_agent\",\n",
        "        \"semantic_logic_agent\": \"semantic_logic_agent\",\n",
        "        \"END\": END\n",
        "    }\n",
        ")\n",
        "\n",
        "workflow.add_edge(\"bpmn_modeler_agent\", \"supervisor\")\n",
        "workflow.add_edge(\"syntax_corrector_agent\", \"supervisor\")\n",
        "workflow.add_edge(\"layout_corrector_agent\", \"supervisor\")\n",
        "workflow.add_edge(\"semantic_logic_agent\", \"supervisor\")\n",
        "\n",
        "\n",
        "supervisor_app = workflow.compile()\n",
        "\n",
        "\n",
        "def run_workflow(source_file: str, bpmn_file: str, run_number: int):\n",
        "    \"\"\"\n",
        "    Sets up and runs a single workflow instance for a given use case.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- STARTING RUN {run_number} FOR {os.path.basename(source_file)} ---\")\n",
        "    print(f\"--- Output will be saved to files starting with: {os.path.splitext(bpmn_file)[0]} ---\\n\")\n",
        "\n",
        "    initial_task_description = f\"{source_file},{bpmn_file}\"\n",
        "    initial_state = {\n",
        "        \"messages\": [HumanMessage(content=f\"Start the process. The initial task for the modeler is: {initial_task_description}\")],\n",
        "        \"file_path\": bpmn_file,\n",
        "        \"source_path\": source_file,\n",
        "        \"task\": \"\",\n",
        "        \"attempt_counts\": {},\n",
        "        \"agent_step_counts\": {},\n",
        "        \"modeler_has_run\": False,\n",
        "    }\n",
        "\n",
        "    final_state = None\n",
        "    try:\n",
        "        for chunk in supervisor_app.stream(initial_state, {\"recursion_limit\": 100}):\n",
        "            final_state = chunk\n",
        "    except Exception as e:\n",
        "        print(f\"\\n!!!!!! An error occurred during the execution for {source_file}, run {run_number} !!!!!!\")\n",
        "        print(f\"Error: {e}\")\n",
        "        with open(\"/content/outputs/error_log.txt\", \"a\") as f:\n",
        "            f.write(f\"Timestamp: {time.ctime()}\\nUseCase: {source_file}, Run: {run_number}\\nError: {e}\\n---\\n\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\n--- SUPERVISOR WORKFLOW COMPLETE FOR RUN {run_number} OF {os.path.basename(source_file)} ---\")\n",
        "    if final_state and final_state.get(\"messages\"):\n",
        "        final_message = final_state[\"messages\"][-1].content\n",
        "        print(\"Final response from the graph:\", final_message, sep='\\n')\n",
        "\n",
        "        summary_filename = f\"{os.path.splitext(bpmn_file)[0]}_summary.txt\"\n",
        "        with open(summary_filename, 'w') as f:\n",
        "            f.write(final_message)\n",
        "        print(f\"Final summary saved to {summary_filename}\")\n",
        "\n",
        "    print(f\"\\n{'='*60}\\n\")\n",
        "    time.sleep(5)\n",
        "\n",
        "# --- MAIN EXECUTION BLOCK ---\n",
        "if __name__ == \"__main__\":\n",
        "    use_case_files = [f\"/content/uc{i}.txt\" for i in range(1, 6)]\n",
        "    runs_per_case = 3\n",
        "    output_directory = \"/content/outputs\"\n",
        "\n",
        "    if not os.path.exists(output_directory):\n",
        "        os.makedirs(output_directory)\n",
        "\n",
        "    for uc_path in use_case_files:\n",
        "        if not os.path.exists(uc_path):\n",
        "            print(f\"WARNING: Source file {uc_path} not found. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        base_name = os.path.splitext(os.path.basename(uc_path))[0]\n",
        "\n",
        "        for i in range(1, runs_per_case + 1):\n",
        "            output_bpmn_file = os.path.join(output_directory, f\"output_{base_name}_run{i}.bpmn\")\n",
        "\n",
        "            run_workflow(\n",
        "                source_file=uc_path,\n",
        "                bpmn_file=output_bpmn_file,\n",
        "                run_number=i\n",
        "            )\n",
        "\n",
        "    print(\"All use cases and runs have been processed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jz806kwlyZ4f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3kH6IzryaAr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJPCl1NByaFT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}